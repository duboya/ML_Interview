## 1. 从优化问题来看

首先，我们要优化的是这个问题 $\min\limits_w E_D(w) + \lambda E_R(w)​$。

其次， $\min\limits_w E_D(w) + \lambda E_R(w)​$ 和 $\min\limits_w E_D(w) \\s.t. E_R(w) \leqslant \eta​$

这个优化问题是等价的，即对一个特定的 $\lambda$ 总存在一个 $\eta​$ 使得这两个问题是等价的（这个是优化里的知识）。

最后，下面这个图表达的其实

 $\min\limits_w E_D(w) \\s.t. E_R(w) \leqslant \eta​$

这个优化问题，**把 $w$ 的解限制在黄色区域内，同时使得经验损失尽可能小**。

![img](https://pic4.zhimg.com/50/v2-82ec609d0958df7ae138c1e08cbe05d6_hd.jpg)![img](https://pic4.zhimg.com/80/v2-82ec609d0958df7ae138c1e08cbe05d6_hd.jpg)

下图是一个更直观的解读：

![img](https://pic2.zhimg.com/80/v2-a026e24156e13a1d14c43df26b9bd2a4_hd.jpg)



## 2. 从梯度角度来看

![img](https://pic1.zhimg.com/80/v2-f6edae58134c5a26687c3883af48d5d5_hd.jpg)

## 3. 从概率角度来看

![img](https://pic2.zhimg.com/80/v2-3aaa69f70754c469bca5c8e4c3e161db_hd.jpg)





## 参考文献

[1] [l1 相比于 l2 为什么容易获得稀疏解？ - 曹荣禹的回答](
https://www.zhihu.com/question/37096933/answer/475278057)

[2] [l1 相比于 l2 为什么容易获得稀疏解？ - 王小明的回答](
https://www.zhihu.com/question/37096933/answer/189905987)

